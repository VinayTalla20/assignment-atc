test_pod:
  image: bats/bats:v1.1.0
  pullPolicy: IfNotPresent

loki:
  enabled: true
  isDefault: true
  url: http://{{(include "loki.serviceName" .)}}:{{ .Values.loki.service.port }}
  gateway:
    enabled: true
  image:
    tag: 2.9.4
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: logging
            operator: In
            values:
            - grafana
  tolerations:
   - key: "logging"
     operator: "Equal"
     value: "grafana"
     effect: "NoSchedule"
  auth_enabled: false
  persistence:
    type: pvc
    enabled: true
    size: 20Gi
    storageClassName: volumestorage
    existingClaim: pvc-storage-prom
  existingSecretForConfig: loki
  config:
    compactor:
      compaction_interval: 10m
      retention_enabled: true
      retention_delete_delay: 2h
      retention_delete_worker_count: 150
      shared_store: filesystem
      working_directory: /data/loki/boltdb-shipper-compactor
    limits_config:
      retention_period: 720h
      enforce_metric_name: false
      max_entries_limit_per_query: 500000
      reject_old_samples: true
      reject_old_samples_max_age: 168h
    server:
      log_level: "error"
    ruler:
      storage:
        type: local
        local:
          directory: /data/loki/rules
      rule_path: /tmp/loki/rules
      alertmanager_url: http://loki-prometheus-alertmanager:80
      enable_alertmanager_discovery: false
      ring:
        kvstore:
          store: inmemory
      enable_api: true
      enable_alertmanager_v2: true

  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45
  livenessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45
  datasource:
    jsonData: {}
    uid: ""

promtail:
  enabled: true
  config:
    logLevel: info
    serverPort: 3101
    clients:
      - url: http://loki-write-headless:3100/loki/api/v1/push
  tolerations:
   - key: "logging"
     operator: "Equal"
     value: "grafana"
     effect: "NoSchedule"

fluent-bit:
  enabled: false

grafana:
  enabled: true
  plugins: 
  - grafana-mongodb-datasource
  # - grafana-clock-panel
  ## You can also use other plugin download URL, as long as they are valid zip files,
  ## and specify the name of the plugin after the semicolon. Like this:
  # - https://grafana.com/api/plugins/marcusolsson-json-datasource/versions/1.3.2/download;marcusolsson-json-datasource
  
  datasources:
     datasources.yaml:
       apiVersion: 1
         # List of data sources to delete from the database.
       deleteDatasources: []
         # - name: Loki
         #   orgId: 1
        
        # Mark provisioned data sources for deletion if they are no longer in a provisioning file.
        # It takes no effect if data sources are already listed in the deleteDatasources section.
        # prune: true   #Availiable in version 11.11
       datasources:
       - name: loki
         type: loki
         isDefault: true
         access: proxy
         enabled: true
         url: http://<lokiserivcename>:3100
         jsonData:
          timeout: 500
          # maxLines: 5000000
          httpHeaderName1: Connection
          httpHeaderName2: Upgrade
         secureJsonData:
          httpHeaderValue1: Upgrade
          httpHeaderValue2: websocket
      
          
  sidecar:
    datasources:
      label: ""
      labelValue: ""
      enabled: false
      # maxLines: 500000
  image:
    repository: grafana/grafana
    tag: 11.0.0
  # replicas: 2
  admin:
    existingSecret: azure-aad
    userKey: admin-user
    passwordKey: admin-password

  readinessProbe:
    httpGet:
      path: /api/health
      port: 3000
      scheme: HTTPS

  livenessProbe:
    httpGet:
      path: /api/health
      port: 3000
      scheme: HTTPS
    initialDelaySeconds: 60
    timeoutSeconds: 30
    failureThreshold: 10

  env:
    GF_FEATURE_TOGGLES_ENABLE: logsInfiniteScrolling, lokiQuerySplitting
    GF_SERVER_DOMAIN: domain.azurefd.net
    GF_SERVER_ROOT_URL: https://domain.azurefd.net/grafana/
    GF_SERVER_SERVE_FROM_SUB_PATH: true
    GF_SERVER_PROTOCOL: https
    GF_SERVER_ENFORCE_DOMAIN: False
    GF_SERVER_CERT_FILE: /etc/certs/grafana.crt
    GF_SERVER_CERT_KEY: /etc/certs/grafana.key
  envValueFrom:
    GF_AUTH_AZUREAD_CLIENT_ID:
        secretKeyRef:
          name: azure-aad
          key: client_id
    GF_AUTH_AZUREAD_CLIENT_SECRET:
        secretKeyRef:
          name: azure-aad
          key: client_secret
  persistence:
    type: pvc
    enabled: true
    size: 8Gi
    storageClassName: grafana
    existingClaim: pvc-grafana

  service:
    enabled: true
    type: ClusterIP
    port: 443
    targetPort: 3000
      # targetPort: 4181 To be used with a proxy extraContainer
    ## Service annotations. Can be templated.
    portName: service
  
  alerting:
     delete_rules.yaml:
       apiVersion: 1
       deleteRules: []      
         
     contact_points_test.yaml:
       apiVersion: 1
       contactPoints: []

  grafana.ini:
      smtp:
        enabled: true
        host: smtp.office365.com:587
        user: username
        password: password
        skip_verify: true
        from_name: Grafana
        from_address: username@username.com
      users:
        viewers_can_edit: true
      auth.azuread:
        name: Azure AD
        enabled: true
        allow_sign_up: true
        scopes: openid email profile
        auth_url: https://login.microsoftonline.com/<TENANT_ID>/oauth2/v2.0/authorize
        token_url: https://login.microsoftonline.com/<TENANT_ID>/oauth2/v2.0/token
        allow_assign_grafana_admin: false
      auth:
        azure_auth_enabled: true
      azure: 
        managed_identity_enabled: true
        managed_identity_client_id: managed_identity_client_id_VALUE

  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: logging
            operator: In
            values:
            - grafana
  tolerations:
   - key: "logging"
     operator: "Equal"
     value: "grafana"
     effect: "NoSchedule"
  

prometheus:
  enabled: true
  isDefault: false
  url: http://{{ include "prometheus.fullname" .}}:{{ .Values.prometheus.server.service.servicePort }}{{ .Values.prometheus.server.prefixURL }}
  datasource:
    jsonData: {}
  alertmanager:
    enabled: false
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: logging
              operator: In
              values:
              - grafana
    tolerations:
    - key: "logging"
      operator: "Equal"
      value: "grafana"
      effect: "NoSchedule" 
    persistentVolume:
      enabled: false
      size: 8Gi
      storageClass: grafana
      existingClaim: pvc-prometheus
  server:
    extraFlags: []
    defaultFlagsOverride:
    - --storage.tsdb.retention.time=30d
    - --config.file=/etc/config/prometheus.yml
    - --storage.tsdb.path=/data
    - --web.console.libraries=/etc/prometheus/console_libraries
    - --web.console.templates=/etc/prometheus/consoles
    - --enable-feature=memory-snapshot-on-shutdown
    - --storage.tsdb.wal-compression
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: logging
              operator: In
              values:
              - grafana
    tolerations:
    - key: "logging"
      operator: "Equal"
      value: "grafana"
      effect: "NoSchedule"
    persistentVolume:
      enabled: true
      size: 8Gi
      storageClass: grafana
      existingClaim: pvc-prometheus
  kube-state-metrics: 
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: logging
              operator: In
              values:
              - grafana
    tolerations:
    - key: "logging"
      operator: "Equal"
      value: "grafana"
      effect: "NoSchedule" 
  prometheus-pushgateway:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions: 
            - key: logging
              operator: In
              values:
              - grafana
    tolerations:
    - key: "logging"
      operator: "Equal"
      value: "grafana"
      effect: "NoSchedule"            
          
filebeat:
  enabled: false
  filebeatConfig:
    filebeat.yml: |
      # logging.level: debug
      filebeat.inputs:
      - type: container
        paths:
          - /var/log/containers/*.log
        processors:
        - add_kubernetes_metadata:
            host: ${NODE_NAME}
            matchers:
            - logs_path:
                logs_path: "/var/log/containers/"
      output.logstash:
        hosts: ["logstash-loki:5044"]

logstash:
  enabled: false
  image: grafana/logstash-output-loki
  imageTag: 1.0.1
  filters:
    main: |-
      filter {
        if [kubernetes] {
          mutate {
            add_field => {
              "container_name" => "%{[kubernetes][container][name]}"
              "namespace" => "%{[kubernetes][namespace]}"
              "pod" => "%{[kubernetes][pod][name]}"
            }
            replace => { "host" => "%{[kubernetes][node][name]}"}
          }
        }
        mutate {
          remove_field => ["tags"]
        }
      }
  outputs:
    main: |-
      output {
        loki {
          url => "http://loki:3100/loki/api/v1/push"
          #username => "test"
          #password => "test"
        }
        # stdout { codec => rubydebug }
      }

# proxy is currently only used by loki test pod
# Note: If http_proxy/https_proxy are set, then no_proxy should include the
# loki service name, so that tests are able to communicate with the loki
# service.
proxy:
  http_proxy: ""
  https_proxy: ""
  no_proxy: ""
